{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jetson Nano를 사용해서 Federated Learning으로 학습 과제\n",
    "* 이전 실습에서 Django를 가지고 서버를 만들고 Federated learning을 구현해보는 실습을 진행하였다.\n",
    "* 이번 과제에서는 Jetson Nano를 사용해서 Federated Learning을 진행해야 한다.\n",
    "\n",
    "* 우선 필요한 패키지를 설치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jetson_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile jetson_client.py\n",
    "# Usage : python jetson_client.py --ip IP --p PORT\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "from random import random\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Quiet tensorflow error messages\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder): # inherits JSONEncoder \n",
    "    def default(self, o):\n",
    "        if isinstance(o, np.ndarray):\n",
    "            return o.tolist()\n",
    "        return json.JSONEncoder.default(self, o)\n",
    "\n",
    "class Client:\n",
    "    def __init__(self, max_round: int, time_delay = 5, suppress=True, num_samples=600, cliend_id = 0, experiment = 1):\n",
    "        \"\"\"\n",
    "        @params: \n",
    "            experiment : Desired data split type (1~4)\n",
    "            max_round : the maximum number of rounds that should be trained (arbitrary integer)\n",
    "            model : the NN model type (either 'ann' or 'cnn')\n",
    "            time_delay : the time delay until the next local check (arbitrary positive integer) \n",
    "                        (Need to increase this value if one round of training takes much longer than current time_delay. \n",
    "                        The reason is that any network communication until next round after the client has already uploaded \n",
    "                        the parameters for current round increases network overhead. Thus, higher time_delay will make communication\n",
    "                        more stable while increasing the absolute time it takes. Requires careful selection of this value.)\n",
    "            suppress : boolean value to print the logs\n",
    "        \n",
    "        @return: \n",
    "            None : Initializes the variables\n",
    "                   Setup the urls for communication\n",
    "                   Fetch client's id from the server\n",
    "                   Downloads MNIST dataset and splits\n",
    "                   Build model\n",
    "        \"\"\"\n",
    "        \n",
    "        '''\n",
    "        Urls\n",
    "        '''\n",
    "        \n",
    "        base_url = f\"http://{IP}:{PORT}/\" # Base Url\n",
    "        self.put_weight_url = base_url + f\"put_weight/{client_id}\"\n",
    "        self.get_weight_url = base_url + \"get_server_weight\" # Url that we send or fetch weight parameters\n",
    "        self.round_url = base_url + \"get_server_round\" \n",
    "        self.put_accuracy_url = base_url + f\"put_accuracy/{client_id}\"\n",
    "        \n",
    "        '''\n",
    "        Initial setup\n",
    "        '''\n",
    "        self.experiment = experiment\n",
    "        self.client_id = client_id\n",
    "        self.time_delay = time_delay\n",
    "        self.suppress = suppress\n",
    "        self.global_round = self.request_global_round()\n",
    "        self.current_round = 0\n",
    "        self.max_round = max_round # Set the maximum number of rounds\n",
    "        \n",
    "        '''\n",
    "        Downloads MNIST dataset and prepares (train_x, train_y), (test_x, test_y)\n",
    "        '''\n",
    "        self.train_images, self.train_labels = None, None\n",
    "        self.test_images, self.test_labels = None, None\n",
    "        self.prepare_images()\n",
    "        \n",
    "        self.train_index_list = None\n",
    "        self.test_index_list = None\n",
    "        self.split_train_images = []\n",
    "        self.split_train_labels = []\n",
    "        \n",
    "        self.local_data_num = 0\n",
    "        self.data_split(num_samples=num_samples)\n",
    "        \n",
    "        '''\n",
    "        Builds model\n",
    "        '''\n",
    "        self.model = None\n",
    "        self.build_cnn_model()\n",
    "        \n",
    "    def prepare_images(self):\n",
    "        \"\"\"\n",
    "        @params: \n",
    "            model : 'ann' or 'cnn'. They need slightly different format for the input. For cnn, we add additional dimension for channel\n",
    "        \n",
    "        @return: \n",
    "            None : Prepares MNIST images in the required format for each model\n",
    "            \n",
    "        \"\"\"\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_images, self.train_labels), (self.test_images, self.test_labels) = mnist.load_data()\n",
    "        self.train_images, self.test_images = self.train_images / 255, self.test_images / 255\n",
    "        \n",
    "        # For CNN, add dummy channel to feed the images to CNN\n",
    "        self.train_images=self.train_images.reshape(-1,28, 28, 1)\n",
    "        self.test_images=self.test_images.reshape(-1,28, 28, 1)\n",
    "            \n",
    "    \n",
    "    def build_cnn_model(self):\n",
    "        \"\"\"\n",
    "        @params: \n",
    "            None\n",
    "        \n",
    "        @return: \n",
    "            None : saves the CNN model in self.model variable \n",
    "        \"\"\"\n",
    "        #This model definition must be same in the server (Federated.py)\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            tf.keras.layers.Dropout(0.25),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dropout(0.5),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "    def data_split(self, num_samples):\n",
    "        \"\"\"\n",
    "        @params: \n",
    "            num_samples : The number of sample images in each client. This value is used for equally\n",
    "                          sized dataset\n",
    "        \n",
    "        @return: \n",
    "            None : Split the dataset depending on the self.experiment value\n",
    "           \n",
    "                If self.experiment is 1: Uniform data split: We take equal amount of data from each class (iid)\n",
    "                If self.experiment is 2: Random data split1: We take equal amount of data, but not uniformly distributed across classes\n",
    "                If self.experiment is 3: Random data split2: We take different amount of data and not uniformly distributed across classes\n",
    "                If self.experiment is 4: Skewed: We take disproportionate amount of data for some classes\n",
    "                        \n",
    "        \"\"\"\n",
    "        if self.train_index_list is None or self.test_index_list is None:\n",
    "            self.train_index_list = [[], [], [], [], [], [], [], [], [], []]\n",
    "            self.test_index_list = [[], [], [], [], [], [], [], [], [], []]\n",
    "            for i, v in enumerate(self.train_labels):\n",
    "                self.train_index_list[v].append(i)\n",
    "\n",
    "            for i, v in enumerate(self.test_labels):\n",
    "                self.test_index_list[v].append(i)\n",
    "\n",
    "        \n",
    "        self.split_train_images = []\n",
    "        self.split_train_labels = []\n",
    "        \n",
    "        if self.experiment == 1: #uniform data split\n",
    "            self.local_data_num = num_samples\n",
    "            \n",
    "            for i in range(len(self.train_index_list)):\n",
    "                indices = self.train_index_list[i]\n",
    "                random_indices = np.random.choice(indices, size=num_samples//10)\n",
    "                \n",
    "                self.split_train_images.extend(self.train_images[random_indices])\n",
    "                self.split_train_labels.extend(self.train_labels[random_indices])\n",
    "            \n",
    "\n",
    "        elif self.experiment == 2: # Randomly selected, equally sized dataset\n",
    "            self.local_data_num = num_samples\n",
    "            random_indices = np.random.choice([i for i in range(len(self.train_labels))], size=num_samples)\n",
    "            self.split_train_images = self.train_images[random_indices]\n",
    "            self.split_train_labels = self.train_labels[random_indices]\n",
    "\n",
    "            counts = [0 for _ in range(10)]\n",
    "            \n",
    "            for label in self.train_labels[random_indices]:\n",
    "                counts[label] += 1\n",
    "            \n",
    "        elif self.experiment == 3: # Randomly selected, differently sized dataset\n",
    "            n = np.random.randint(1, num_samples)\n",
    "            self.local_data_num = n\n",
    "            random_indices = np.random.choice([i for i in range(len(self.train_labels))], size=n)\n",
    "            self.split_train_images = self.train_images[random_indices]\n",
    "            self.split_train_labels = self.train_labels[random_indices]\n",
    "            \n",
    "\n",
    "            counts = [0 for _ in range(10)]\n",
    "            \n",
    "            for label in self.train_labels[random_indices]:\n",
    "                counts[label] += 1\n",
    "  \n",
    "        elif self.experiment == 4: #Skewed\n",
    "            temp = [i for i in range(10)]\n",
    "            skewed_numbers = np.random.choice(temp, np.random.randint(1, 10))\n",
    "            non_skewed_numbers = list(set(temp)-set(skewed_numbers))\n",
    "            N = 0\n",
    "            \n",
    "            counts = [0 for _ in range(10)]\n",
    "            \n",
    "            for i in skewed_numbers:\n",
    "                n = np.random.randint(50, 60)\n",
    "                N += n\n",
    "                \n",
    "                indices = self.train_index_list[i]\n",
    "                random_indices = np.random.choice(indices, size=n)\n",
    "                \n",
    "                self.split_train_images.extend(self.train_images[random_indices])\n",
    "                self.split_train_labels.extend(self.train_labels[random_indices])\n",
    "                \n",
    "                counts[i] += n\n",
    "            \n",
    "                \n",
    "            for i in non_skewed_numbers:\n",
    "                n = np.random.randint(1, 10)\n",
    "                N += n\n",
    "                \n",
    "                indices = self.train_index_list[i]\n",
    "                random_indices = np.random.choice(indices, size=n)\n",
    "                \n",
    "                self.split_train_images.extend(self.train_images[random_indices])\n",
    "                self.split_train_labels.extend(self.train_labels[random_indices])\n",
    "                \n",
    "                counts[i] += n\n",
    "            \n",
    "            self.local_data_num = N\n",
    "        \n",
    "        self.split_train_images = np.array(self.split_train_images)\n",
    "        self.split_train_labels = np.array(self.split_train_labels)\n",
    "        self.update_total_num_data(self.local_data_num)    \n",
    "\n",
    "        \n",
    "        \n",
    "    def update_total_num_data(self, num_data):\n",
    "        \"\"\"\n",
    "        num_data : the number of training images that the current client has\n",
    "        \n",
    "        update the total number of training images that is stored in the server\n",
    "        \"\"\"\n",
    "        local_num_data_to_json = json.dumps(num_data)\n",
    "        requests.put(self.total_num_data_url, data=local_num_data_to_json)\n",
    "\n",
    "    \n",
    "    def request_global_round(self):\n",
    "        \"\"\"\n",
    "        result : Current global round that the server is in\n",
    "        \"\"\"\n",
    "        result = requests.get(self.round_url)\n",
    "        result = result.json()\n",
    "        return result\n",
    "    \n",
    "    def request_global_weight(self):\n",
    "        \"\"\"\n",
    "        global_weight : Up-to-date version of the model parameters\n",
    "        \"\"\"\n",
    "        result = requests.get(self.weight_url)\n",
    "        result_data = result.json()\n",
    "        \n",
    "        global_weight = None\n",
    "        if result_data is not None:\n",
    "            global_weight = []\n",
    "            for i in range(len(result_data)):\n",
    "                temp = np.array(result_data[i], dtype=np.float32)\n",
    "                global_weight.append(temp)\n",
    "            \n",
    "        return global_weight\n",
    "\n",
    "    def upload_local_weight(self, local_weight=[]):\n",
    "        \"\"\"\n",
    "        local_weight : the local weight that current client has converged to\n",
    "        \n",
    "        Add current client's weights to the server (Server accumulates these from multiple clients and computes the global weight)\n",
    "        \"\"\"\n",
    "        local_weight_to_json = json.dumps(local_weight, cls=NumpyEncoder)\n",
    "        requests.put(self.put_weight_url, data=local_weight_to_json)\n",
    "        \n",
    "    def upload_local_accuracy(self, accuracy):\n",
    "        accuracy_dic = {'accuracy': accuracy}\n",
    "        accuracy_in_json = json.dumps(accuracy_dic)\n",
    "        requests.get(self.put_accuracy_url, data = accuracy_in_json)\n",
    "        \n",
    "    def validation(self, local_weight=[]):\n",
    "        \"\"\"\n",
    "        local_weight : the current client's weights\n",
    "        \n",
    "        acc : test accuracy of the current client's model\n",
    "        \"\"\"\n",
    "        if local_weight is not None:\n",
    "            self.model.set_weights(local_weight)\n",
    "            acc = self.model.evaluate(self.test_images, self.test_labels, verbose=0 if self.suppress else 1)\n",
    "            self.upload_local_accuracy(acc)\n",
    "            e = {out: acc[i] for i, out in enumerate(self.model.metrics_names)}\n",
    "\n",
    "            return acc\n",
    "        \n",
    "    def train_local_model(self):\n",
    "        \"\"\"\n",
    "        local_weight : local weight of the current client after training\n",
    "        \"\"\"\n",
    "        global_weight = self.request_global_weight()\n",
    "        if global_weight != None:\n",
    "            global_weight = np.array(global_weight)\n",
    "            self.model.set_weights(global_weight)\n",
    "        \n",
    "        self.model.fit(self.split_train_images, self.split_train_labels, epochs=10, batch_size=16, verbose=0)\n",
    "        local_weight = self.model.get_weights()\n",
    "        return local_weight\n",
    "    \n",
    "    def task(self):\n",
    "        \"\"\"\n",
    "        Federated learning task\n",
    "        1. If the current round is larger than the max round that we set, finish\n",
    "        2. If the global round = current client's round, the client needs update\n",
    "        3. Otherwise, we need to wait until other clients to finish\n",
    "        \"\"\"\n",
    "        \n",
    "        #this is for executing on multiple devices\n",
    "        self.global_round = self.request_global_round()\n",
    "\n",
    "        if self.current_round >= self.max_round:\n",
    "            print(f\"Client {self.fed_id} finished\")\n",
    "            return \n",
    "\n",
    "        if self.global_round == self.current_round: #need update \n",
    "            global_weight = self.request_global_weight()\n",
    "            local_weight = self.train_local_model()\n",
    "            acc = self.validation(local_weight)\n",
    "            self.upload_local_weight(local_weight)\n",
    "            self.current_round += 1\n",
    "            time.sleep(self.time_delay)\n",
    "            return self.task()\n",
    "\n",
    "        else: #need to wait until other clients finish\n",
    "            time.sleep(self.time_delay * 2)\n",
    "            return self.task()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Usage --ip {ip} --p {port} --max {max round} --delay {time delay} --num {num samples}\")\n",
    "    parser.add_argument(\"--ip\", type=str, help=\"base ip address\", default=\"127.0.0.1\")\n",
    "    parser.add_argument(\"--max\", type=int, help=\"max round\", default=5)\n",
    "    parser.add_argument(\"--delay\", type=int, help=\"time delay\", default=5)\n",
    "    parser.add_argument(\"--num\", type=int, help=\"num samples\", default=600)\n",
    "    parser.add_argument(\"--id\", type=int, help=\"client id\", default=0)\n",
    "    parser.add_argumetn(\"--exp\", type=int, help=\"experiment number\", default=1) #2,3,4\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    client = Client(max_round = args.max, \n",
    "                    time_delay = args.delay, \n",
    "                    num_samples = args.num,  \n",
    "                    suppress=True, \n",
    "                    cliend_id = args.id, \n",
    "                    experiment = args.exp)\n",
    "    client.task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting jetson_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile jetson_server.py\n",
    "import paramiko\n",
    "import getpass\n",
    "from ping3 import ping\n",
    "import time\n",
    "import argparse\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Jetson:\n",
    "    def __init__(self, min_port, max_port):\n",
    "        assert int(min_port) < int(max_port), \"max port must be >= min port\"\n",
    "        self.address = \"147.47.200.209\"\n",
    "        self.host_address = args.serverip\n",
    "        self.username, self.password = \"jetson\", \"jetson\"\n",
    "        self.ports = [i for i in range(int(min_port), int(max_port)+1)]        \n",
    "        self.available = []\n",
    "        \n",
    "    def check(self):\n",
    "        # check which clients are online \n",
    "        cli = paramiko.SSHClient()\n",
    "        cli.set_missing_host_key_policy(paramiko.AutoAddPolicy)       \n",
    "        \n",
    "        for port in self.ports:\n",
    "            try:\n",
    "                cli.connect(hostname=self.address, port=port, username=self.username, password=self.password)\n",
    "                stdin, stdout, stderr = cli.exec_command(\"ls\")\n",
    "                lines = stdout.readlines()\n",
    "                self.available.append(port)\n",
    "\n",
    "            except:\n",
    "                print(f\"Port {port} Error\")\n",
    "                continue\n",
    "                \n",
    "        cli.close() \n",
    "        \n",
    "\n",
    "    def start_fed(self, experiment, max_round, time_delay, num_samples):\n",
    "        self.cli = paramiko.SSHClient()\n",
    "        self.cli.set_missing_host_key_policy(paramiko.AutoAddPolicy)       \n",
    "        \n",
    "        for i, port in tqdm(enumerate(self.available), desc=\"Sending commands\"):\n",
    "            self.cli.connect(hostname=self.address, port=port, username=self.username, password=self.password)\n",
    "            command = f\"python jetson_client.py --ip {self.host_address} --max {max_round} --delay {time_delay} --num {num_samples} --id {i} --exp {experiment}\"\n",
    "            if i == 0:\n",
    "                print(f\"Sending command: {command}\")\n",
    "            stdin, stdout, stderr = self.cli.exec_command(command)\n",
    "        self.cli.close()\n",
    "\n",
    "    def init_jetson_nanos(self):\n",
    "        self.check()\n",
    "            \n",
    "if __name__ ==\"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Usage --ip {ip} --p {port} --max {max round} --delay {time delay} --num {num samples}\")\n",
    "    parser.add_argument(\"--minp\", type=int, help=\"min port\", default=20101)\n",
    "    parser.add_argument(\"--maxp\", type=int, help=\"max port\", default=20106)\n",
    "    parser.add_argument(\"--mr\", type=int, help=\"total # of rounds to run\", default=5)\n",
    "    parser.add_argument(\"--delay\", type=int, help=\"time delay\", default=5)\n",
    "    parser.add_argument(\"--num\", type=int, help=\"num samples\", default=600)\n",
    "    parser.add_argument(\"--exp\", type=int, help=\"experiment number\", default=1) #2,3,4\n",
    "    parser.add_argument(\"--serverip\", type=str, help=\"server ip address\", default=\"localhost:22222\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    ###### VARIABLES ######\n",
    "    MIN_PORT = args.minp\n",
    "    MAX_PORT = args.maxp\n",
    "    EXPERIMENT = args.exp\n",
    "    MAX_ROUND = args.mr\n",
    "    TIME_DELAY = args.delay\n",
    "    CLIENT_NUM = 1 + (MAX_PORT-MIN_PORT)\n",
    "    SERVER_ADD = args.serverip\n",
    "    assert (CLIENT_NUM > 0)\n",
    "    ###### INITIALIZE SERVER ######\n",
    "    import requests\n",
    "    init = requests.get(f\"http://{SERVER_ADD}/initialize/{CLIENT_NUM}/{EXPERIMENT}/{MAX_ROUND}\")\n",
    "    reset = requests.get(f\"http://{SERVER_ADD}/reset\")\n",
    "    print(init, init.text)\n",
    "\n",
    "    jetson = Jetson(min_port = MIN_PORT, max_port=MAX_PORT)\n",
    "    jetson.init_jetson_nanos()\n",
    "    jetson.start_fed(experiment=args.exp, \n",
    "                     max_round=args.mr,\n",
    "                     time_delay=args.delay, \n",
    "                     num_samples=args.num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\", line 169, in _new_conn\r\n",
      "    conn = connection.create_connection(\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py\", line 96, in create_connection\r\n",
      "    raise err\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/util/connection.py\", line 86, in create_connection\r\n",
      "    sock.connect(sa)\r\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 699, in urlopen\r\n",
      "    httplib_response = self._make_request(\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 394, in _make_request\r\n",
      "    conn.request(method, url, **httplib_request_kw)\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\", line 234, in request\r\n",
      "    super(HTTPConnection, self).request(method, url, body=body, headers=headers)\r\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1252, in request\r\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\r\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1298, in _send_request\r\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\r\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1247, in endheaders\r\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\r\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 1007, in _send_output\r\n",
      "    self.send(msg)\r\n",
      "  File \"/usr/lib/python3.8/http/client.py\", line 947, in send\r\n",
      "    self.connect()\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\", line 200, in connect\r\n",
      "    conn = self._new_conn()\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\", line 181, in _new_conn\r\n",
      "    raise NewConnectionError(\r\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f60d62fd2b0>: Failed to establish a new connection: [Errno 111] Connection refused\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/adapters.py\", line 439, in send\r\n",
      "    resp = conn.urlopen(\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\", line 755, in urlopen\r\n",
      "    retries = retries.increment(\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/urllib3/util/retry.py\", line 574, in increment\r\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\r\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=22222): Max retries exceeded with url: /initialize/6/1/5 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f60d62fd2b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"jetson_server.py\", line 74, in <module>\r\n",
      "    init = requests.get(f\"http://localhost:22222/initialize/{CLIENT_NUM}/{EXPERIMENT}/{MAX_ROUND}\")\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/api.py\", line 75, in get\r\n",
      "    return request('get', url, params=params, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/api.py\", line 61, in request\r\n",
      "    return session.request(method=method, url=url, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 542, in request\r\n",
      "    resp = self.send(prep, **send_kwargs)\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/sessions.py\", line 655, in send\r\n",
      "    r = adapter.send(request, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/requests/adapters.py\", line 516, in send\r\n",
      "    raise ConnectionError(e, request=request)\r\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=22222): Max retries exceeded with url: /initialize/6/1/5 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f60d62fd2b0>: Failed to establish a new connection: [Errno 111] Connection refused'))\r\n"
     ]
    }
   ],
   "source": [
    "!python3 jetson_server.py --minp 20131 --maxp 20136 --mr 5 --delay 5 --num 600 --exp 1 --serverip \"147.47.200.178:22222\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 10\n",
    "* 실습에서 컴퓨터 하나로 Federated learning을 진행해 보았다.\n",
    "* 이번 과제는 미리 설치해 놓은 여러 대의 Jetson Nano를 사용해서 실제로 네트워크 상에서 Federated learning을 진행하는 것이다. \n",
    "* 4개의 실험 (experiment:1,2,3,4)을 진행해보고, 결과를 비교하여 보고서로 작성하여 제출. (형식 자유)\n",
    "* 보고서에는 실습에서의 결과와의 비교가 포함되어야 한다. (?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
